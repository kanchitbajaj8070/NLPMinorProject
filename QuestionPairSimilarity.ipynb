{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def read_data():\n",
    "    df = pd.read_csv(\"train.csv\",nrows=40000)\n",
    "    print (\"Shape of base training File = \", df.shape)\n",
    "    df.drop_duplicates(inplace=True)\n",
    "    df.dropna(inplace=True)\n",
    "    print(\"Shape of base training data after cleaning = \", df.shape)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of base training File =  (40000, 6)\n",
      "Shape of base training data after cleaning =  (40000, 6)\n",
      "          id   qid1   qid2                                          question1  \\\n",
      "38756  38756  70341  70342     Do you make money by writing answers on Quora?   \n",
      "33207  33207  61043  61044  What are some pros in investing in emerging ma...   \n",
      "39518  39518  71625  71626            How do I crack SPHR certification exam?   \n",
      "4313    4313   8529   8530  Velocity of air at the outlet of air condition...   \n",
      "12873  12873  24761  24762  Yale University: What was it like to attend Ya...   \n",
      "\n",
      "                                               question2  is_duplicate  \n",
      "38756  Do we earn something when we write answers for...             1  \n",
      "33207  What are pros and cons of investing in emergin...             1  \n",
      "39518     How can I pass the MB6-885 certification exam?             0  \n",
      "4313   Can I replace core i3 first generation with a ...             0  \n",
      "12873  Yale University: What was it like to attend Ya...             0  \n",
      "(800, 6)\n"
     ]
    }
   ],
   "source": [
    "df = read_data()\n",
    "df_train, df_test = train_test_split(df, test_size = 0.02)\n",
    "print (df_train.head())\n",
    "print (df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate Count = 14588 , Non Duplicate Count = 24612\n",
      "Unique Questions = 71092\n",
      "Count of Quesitons appearing more than once = 5146\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import operator\n",
    "\n",
    "def eda(df):\n",
    "    print (\"Duplicate Count = %s , Non Duplicate Count = %s\" \n",
    "           %(df.is_duplicate.value_counts()[1],df.is_duplicate.value_counts()[0]))\n",
    "    \n",
    "    question_ids_combined = df.qid1.tolist() + df.qid2.tolist()\n",
    "    \n",
    "    print (\"Unique Questions = %s\" %(len(np.unique(question_ids_combined))))\n",
    "    \n",
    "    question_ids_counter = Counter(question_ids_combined)\n",
    "    sorted_question_ids_counter = sorted(question_ids_counter.items(), key=operator.itemgetter(1))\n",
    "    question_appearing_more_than_once = [i for i in question_ids_counter.values() if i > 1]\n",
    "    print (\"Count of Quesitons appearing more than once = %s\" %(len(question_appearing_more_than_once)))\n",
    "    \n",
    "    \n",
    "eda(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in c:\\users\\twink\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (3.8.1)\n",
      "Requirement already satisfied: scipy>=0.18.1 in c:\\users\\twink\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from gensim) (1.4.1)\n",
      "Requirement already satisfied: six>=1.5.0 in c:\\users\\twink\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from gensim) (1.12.0)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\twink\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from gensim) (1.9.0)\n",
      "Requirement already satisfied: numpy>=1.11.3 in c:\\users\\twink\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from gensim) (1.16.1)\n",
      "Requirement already satisfied: boto>=2.32 in c:\\users\\twink\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from smart-open>=1.8.1->gensim) (2.49.0)\n",
      "Requirement already satisfied: requests in c:\\users\\twink\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from smart-open>=1.8.1->gensim) (2.22.0)\n",
      "Requirement already satisfied: boto3 in c:\\users\\twink\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from smart-open>=1.8.1->gensim) (1.11.9)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\users\\twink\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from requests->smart-open>=1.8.1->gensim) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\twink\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from requests->smart-open>=1.8.1->gensim) (2019.9.11)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\twink\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from requests->smart-open>=1.8.1->gensim) (1.25.7)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in c:\\users\\twink\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from requests->smart-open>=1.8.1->gensim) (2.8)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in c:\\users\\twink\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from boto3->smart-open>=1.8.1->gensim) (0.9.4)\n",
      "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in c:\\users\\twink\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from boto3->smart-open>=1.8.1->gensim) (0.3.2)\n",
      "Requirement already satisfied: botocore<1.15.0,>=1.14.9 in c:\\users\\twink\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from boto3->smart-open>=1.8.1->gensim) (1.14.9)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in c:\\users\\twink\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from botocore<1.15.0,>=1.14.9->boto3->smart-open>=1.8.1->gensim) (2.8.0)\n",
      "Requirement already satisfied: docutils<0.16,>=0.10 in c:\\users\\twink\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from botocore<1.15.0,>=1.14.9->boto3->smart-open>=1.8.1->gensim) (0.15.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.0.2; however, version 20.1.1 is available.\n",
      "You should consider upgrading via the 'c:\\users\\twink\\appdata\\local\\programs\\python\\python37\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\twink\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "c:\\users\\twink\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of words in the dictionary = 7009\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import gensim\n",
    "from gensim import corpora\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import *\n",
    "\n",
    "words = re.compile(r\"\\w+\",re.I)\n",
    "stopword = stopwords.words('english')\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "def tokenize_questions(df):\n",
    "    question_1_tokenized = []\n",
    "    question_2_tokenized = []\n",
    "\n",
    "    for q in df.question1.tolist():\n",
    "        question_1_tokenized.append([stemmer.stem(i.lower()) for i in words.findall(q) if i not in stopword])\n",
    "\n",
    "    for q in df.question2.tolist():\n",
    "        question_2_tokenized.append([stemmer.stem(i.lower()) for i in words.findall(q) if i not in stopword])\n",
    "\n",
    "    df[\"Question_1_tok\"] = question_1_tokenized\n",
    "    df[\"Question_2_tok\"] = question_2_tokenized\n",
    "    \n",
    "    return df\n",
    "\n",
    "def train_dictionary(df):\n",
    "    \n",
    "    questions_tokenized = df.Question_1_tok.tolist() + df.Question_2_tok.tolist()\n",
    "    \n",
    "    dictionary = corpora.Dictionary(questions_tokenized)\n",
    "    dictionary.filter_extremes(no_below=5, no_above=0.8)\n",
    "    dictionary.compactify()\n",
    "    \n",
    "    return dictionary\n",
    "    \n",
    "df_train = tokenize_questions(df_train)\n",
    "dictionary = train_dictionary(df_train)\n",
    "print (\"No of words in the dictionary = %s\" %len(dictionary.token2id))\n",
    "\n",
    "df_test = tokenize_questions(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>Question_1_tok</th>\n",
       "      <th>Question_2_tok</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>38756</th>\n",
       "      <td>38756</td>\n",
       "      <td>70341</td>\n",
       "      <td>70342</td>\n",
       "      <td>Do you make money by writing answers on Quora?</td>\n",
       "      <td>Do we earn something when we write answers for...</td>\n",
       "      <td>1</td>\n",
       "      <td>[do, make, money, write, answer, quora]</td>\n",
       "      <td>[do, earn, someth, write, answer, quora]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33207</th>\n",
       "      <td>33207</td>\n",
       "      <td>61043</td>\n",
       "      <td>61044</td>\n",
       "      <td>What are some pros in investing in emerging ma...</td>\n",
       "      <td>What are pros and cons of investing in emergin...</td>\n",
       "      <td>1</td>\n",
       "      <td>[what, pro, invest, emerg, market]</td>\n",
       "      <td>[what, pro, con, invest, emerg, market]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39518</th>\n",
       "      <td>39518</td>\n",
       "      <td>71625</td>\n",
       "      <td>71626</td>\n",
       "      <td>How do I crack SPHR certification exam?</td>\n",
       "      <td>How can I pass the MB6-885 certification exam?</td>\n",
       "      <td>0</td>\n",
       "      <td>[how, i, crack, sphr, certif, exam]</td>\n",
       "      <td>[how, i, pass, mb6, 885, certif, exam]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4313</th>\n",
       "      <td>4313</td>\n",
       "      <td>8529</td>\n",
       "      <td>8530</td>\n",
       "      <td>Velocity of air at the outlet of air condition...</td>\n",
       "      <td>Can I replace core i3 first generation with a ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[veloc, air, outlet, air, condition, mayb, say...</td>\n",
       "      <td>[can, i, replac, core, i3, first, gener, core,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12873</th>\n",
       "      <td>12873</td>\n",
       "      <td>24761</td>\n",
       "      <td>24762</td>\n",
       "      <td>Yale University: What was it like to attend Ya...</td>\n",
       "      <td>Yale University: What was it like to attend Ya...</td>\n",
       "      <td>0</td>\n",
       "      <td>[yale, univers, what, like, attend, yale, 1990]</td>\n",
       "      <td>[yale, univers, what, like, attend, yale, 1970]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id   qid1   qid2                                          question1  \\\n",
       "38756  38756  70341  70342     Do you make money by writing answers on Quora?   \n",
       "33207  33207  61043  61044  What are some pros in investing in emerging ma...   \n",
       "39518  39518  71625  71626            How do I crack SPHR certification exam?   \n",
       "4313    4313   8529   8530  Velocity of air at the outlet of air condition...   \n",
       "12873  12873  24761  24762  Yale University: What was it like to attend Ya...   \n",
       "\n",
       "                                               question2  is_duplicate  \\\n",
       "38756  Do we earn something when we write answers for...             1   \n",
       "33207  What are pros and cons of investing in emergin...             1   \n",
       "39518     How can I pass the MB6-885 certification exam?             0   \n",
       "4313   Can I replace core i3 first generation with a ...             0   \n",
       "12873  Yale University: What was it like to attend Ya...             0   \n",
       "\n",
       "                                          Question_1_tok  \\\n",
       "38756            [do, make, money, write, answer, quora]   \n",
       "33207                 [what, pro, invest, emerg, market]   \n",
       "39518                [how, i, crack, sphr, certif, exam]   \n",
       "4313   [veloc, air, outlet, air, condition, mayb, say...   \n",
       "12873    [yale, univers, what, like, attend, yale, 1990]   \n",
       "\n",
       "                                          Question_2_tok  \n",
       "38756           [do, earn, someth, write, answer, quora]  \n",
       "33207            [what, pro, con, invest, emerg, market]  \n",
       "39518             [how, i, pass, mb6, 885, certif, exam]  \n",
       "4313   [can, i, replac, core, i3, first, gener, core,...  \n",
       "12873    [yale, univers, what, like, attend, yale, 1970]  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39200, 7009)\n",
      "(39200, 7009)\n"
     ]
    }
   ],
   "source": [
    "def get_vectors(df, dictionary):\n",
    "    \n",
    "    question1_vec = [dictionary.doc2bow(text) for text in df.Question_1_tok.tolist()]\n",
    "    question2_vec = [dictionary.doc2bow(text) for text in df.Question_2_tok.tolist()]\n",
    "    \n",
    "    question1_csc = gensim.matutils.corpus2csc(question1_vec, num_terms=len(dictionary.token2id))\n",
    "    question2_csc = gensim.matutils.corpus2csc(question2_vec, num_terms=len(dictionary.token2id))\n",
    "    \n",
    "    return question1_csc.transpose(),question2_csc.transpose()\n",
    "\n",
    "\n",
    "q1_csc, q2_csc = get_vectors(df_train, dictionary)\n",
    "\n",
    "print (q1_csc.shape)\n",
    "print (q2_csc.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cosine_sim sample= \n",
      " [0.6666666666666669, 0.9128709291752769]\n",
      "manhattan_dis sample = \n",
      " [4.0, 1.0]\n",
      "eucledian_dis sample = \n",
      " [2.0, 1.0]\n",
      "jaccard_dis sample = \n",
      " [0.5, 0.8333333333333334]\n",
      "minkowsk_dis sample = \n",
      " [2.0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity as cs\n",
    "from sklearn.metrics.pairwise import manhattan_distances as md\n",
    "from sklearn.metrics.pairwise import euclidean_distances as ed\n",
    "from sklearn.metrics import jaccard_similarity_score as jsc\n",
    "from sklearn.neighbors import DistanceMetric\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "minkowski_dis = DistanceMetric.get_metric('minkowski')\n",
    "mms_scale_man = MinMaxScaler()\n",
    "mms_scale_euc = MinMaxScaler()\n",
    "mms_scale_mink = MinMaxScaler()\n",
    "\n",
    "def get_similarity_values(q1_csc, q2_csc):\n",
    "    cosine_sim = []\n",
    "    manhattan_dis = []\n",
    "    eucledian_dis = []\n",
    "    jaccard_dis = []\n",
    "    minkowsk_dis = []\n",
    "    \n",
    "    for i,j in zip(q1_csc, q2_csc):\n",
    "        sim = cs(i,j)\n",
    "        cosine_sim.append(sim[0][0])\n",
    "        sim = md(i,j)\n",
    "        manhattan_dis.append(sim[0][0])\n",
    "        sim = ed(i,j)\n",
    "        eucledian_dis.append(sim[0][0])\n",
    "        i_ = i.toarray()\n",
    "        j_ = j.toarray()\n",
    "        try:\n",
    "            sim = jsc(i_,j_)\n",
    "            jaccard_dis.append(sim)\n",
    "        except:\n",
    "            jaccard_dis.append(0)\n",
    "            \n",
    "        sim = minkowski_dis.pairwise(i_,j_)\n",
    "        minkowsk_dis.append(sim[0][0])\n",
    "    \n",
    "    return cosine_sim, manhattan_dis, eucledian_dis, jaccard_dis, minkowsk_dis    \n",
    "\n",
    "\n",
    "cosine_sim, manhattan_dis, eucledian_dis, jaccard_dis, minkowsk_dis = get_similarity_values(q1_csc, q2_csc)\n",
    "print (\"cosine_sim sample= \\n\", cosine_sim[0:2])\n",
    "print (\"manhattan_dis sample = \\n\", manhattan_dis[0:2])\n",
    "print (\"eucledian_dis sample = \\n\", eucledian_dis[0:2])\n",
    "print (\"jaccard_dis sample = \\n\", jaccard_dis[0:2])\n",
    "print (\"minkowsk_dis sample = \\n\", minkowsk_dis[0:2])\n",
    "\n",
    "eucledian_dis_array = np.array(eucledian_dis).reshape(-1,1)\n",
    "manhattan_dis_array = np.array(manhattan_dis).reshape(-1,1)\n",
    "minkowsk_dis_array = np.array(minkowsk_dis).reshape(-1,1)\n",
    "    \n",
    "manhattan_dis_array = mms_scale_man.fit_transform(manhattan_dis_array)\n",
    "eucledian_dis_array = mms_scale_euc.fit_transform(eucledian_dis_array)\n",
    "minkowsk_dis_array = mms_scale_mink.fit_transform(minkowsk_dis_array)\n",
    "\n",
    "eucledian_dis = eucledian_dis_array.flatten()\n",
    "manhattan_dis = manhattan_dis_array.flatten()\n",
    "minkowsk_dis = minkowsk_dis_array.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The calculated log loss value on the test set for cosine sim is = 1.701234\n",
      "The calculated log loss value on the test set for manhattan sim is = 2.846829\n",
      "The calculated log loss value on the test set for euclidean sim is = 2.489169\n",
      "The calculated log loss value on the test set for jaccard sim is = 3.267839\n",
      "The calculated log loss value on the test set for minkowski sim is = 2.489169\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "\n",
    "def calculate_logloss(y_true, y_pred):\n",
    "    loss_cal = log_loss(y_true, y_pred)\n",
    "    return loss_cal\n",
    "\n",
    "q1_csc_test, q2_csc_test = get_vectors(df_test, dictionary)\n",
    "y_pred_cos, y_pred_man, y_pred_euc, y_pred_jac, y_pred_mink = get_similarity_values(q1_csc_test, q2_csc_test)\n",
    "y_true = df_test.is_duplicate.tolist()\n",
    "\n",
    "y_pred_man_array = mms_scale_man.transform(np.array(y_pred_man).reshape(-1,1))\n",
    "y_pred_man = y_pred_man_array.flatten()\n",
    "\n",
    "y_pred_euc_array = mms_scale_euc.transform(np.array(y_pred_euc).reshape(-1,1))\n",
    "y_pred_euc = y_pred_euc_array.flatten()\n",
    "\n",
    "y_pred_mink_array = mms_scale_mink.transform(np.array(y_pred_mink).reshape(-1,1))\n",
    "y_pred_mink = y_pred_mink_array.flatten()\n",
    "\n",
    "logloss = calculate_logloss(y_true, y_pred_cos)\n",
    "print (\"The calculated log loss value on the test set for cosine sim is = %f\" %logloss)\n",
    "\n",
    "logloss = calculate_logloss(y_true, y_pred_man)\n",
    "print (\"The calculated log loss value on the test set for manhattan sim is = %f\" %logloss)\n",
    "\n",
    "logloss = calculate_logloss(y_true, y_pred_euc)\n",
    "print (\"The calculated log loss value on the test set for euclidean sim is = %f\" %logloss)\n",
    "\n",
    "logloss = calculate_logloss(y_true, y_pred_jac)\n",
    "print (\"The calculated log loss value on the test set for jaccard sim is = %f\" %logloss)\n",
    "\n",
    "logloss = calculate_logloss(y_true, y_pred_mink)\n",
    "print (\"The calculated log loss value on the test set for minkowski sim is = %f\" %logloss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\twink\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "c:\\users\\twink\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1,\n",
       "  gamma='auto_deprecated', kernel='rbf', max_iter=-1, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "X_train = pd.DataFrame({\"cos\" : cosine_sim, \"man\" : manhattan_dis, \"euc\" : eucledian_dis, \"jac\" : jaccard_dis, \"min\" : minkowsk_dis})\n",
    "y_train = df_train.is_duplicate\n",
    "\n",
    "X_test = pd.DataFrame({\"cos\" : y_pred_cos, \"man\" : y_pred_man, \"euc\" : y_pred_euc, \"jac\" : y_pred_jac, \"min\" : y_pred_mink})\n",
    "y_test = y_true\n",
    "\n",
    "rfr = RandomForestRegressor()\n",
    "rfr.fit(X_train, y_train)\n",
    "\n",
    "svr = SVR()\n",
    "svr.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The calculated log loss value on the test set using RFR is = 0.681303\n",
      "The calculated log loss value on the test set using SVR is = 0.682930\n"
     ]
    }
   ],
   "source": [
    "y_rfr_predicted = rfr.predict(X_test)\n",
    "y_svr_predicted = svr.predict(X_test)\n",
    "\n",
    "logloss_rfr = calculate_logloss(y_test, y_rfr_predicted)\n",
    "logloss_svr = calculate_logloss(y_test, y_svr_predicted)\n",
    "\n",
    "print (\"The calculated log loss value on the test set using RFR is = %f\" %logloss_rfr)\n",
    "print (\"The calculated log loss value on the test set using SVR is = %f\" %logloss_svr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
